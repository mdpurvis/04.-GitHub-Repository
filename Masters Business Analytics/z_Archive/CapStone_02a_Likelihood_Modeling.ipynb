{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Data Cleaning\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# EDA - Data Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "import statsmodels.api as stats\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "plt.style.use('seaborn') # pretty matplotlib plots\n",
    "plt.rc('font', size=14)\n",
    "plt.rc('figure', titlesize=18)\n",
    "plt.rc('axes', labelsize=15)\n",
    "plt.rc('axes', titlesize=18)\n",
    "\n",
    "#Modeling\n",
    "from sklearn import (datasets,\n",
    "                     metrics,\n",
    "                     model_selection as skms,\n",
    "                     naive_bayes,\n",
    "                     neighbors)\n",
    "\n",
    "from sklearn.linear_model import (LogisticRegression,\n",
    "                                 SGDClassifier)\n",
    "\n",
    "from sklearn.model_selection import (cross_val_score,\n",
    "                                     cross_val_predict,\n",
    "                                     train_test_split,\n",
    "                                     GridSearchCV)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from sklearn.metrics import (accuracy_score,\n",
    "                             precision_score,\n",
    "                             recall_score,\n",
    "                             confusion_matrix,\n",
    "                             f1_score,\n",
    "                             roc_curve,\n",
    "                             auc,\n",
    "                             classification_report,\n",
    "                             precision_recall_curve)\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV \n",
    "\n",
    "\n",
    "# Remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# logistic regression model\n",
    "import statsmodels.api as sm \n",
    "\n",
    "pd.set_option('display.max_rows', 90)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_model_run(X_train, X_test, y_train, y_test):\n",
    "    logistic_regression = LogisticRegression(n_jobs=-1, random_state=15).fit(X_train, y_train)\n",
    "    model_pred = logistic_regression.predict(X_test)\n",
    "\n",
    "    acc_logistic_regression = round(logistic_regression.score(X_test, y_test) * 100, 2)\n",
    "    prec_logistic_regression = round(precision_score(y_pred=model_pred, y_true=y_test)* 100, 2)\n",
    "    recall_logistic_regression = round(recall_score(y_pred=model_pred, y_true=y_test)* 100, 2)\n",
    "    f1_logistic_regression = round(f1_score(y_pred=model_pred, y_true=y_test)* 100, 2)\n",
    "    \n",
    "    print('Summary of Modeled Results: ')\n",
    "    print('   General Accuracy: {:6,.1f}%'.format(acc_logistic_regression))\n",
    "    print('   ROC AUC Score:    {:6,.1f}%'.format(metrics.roc_auc_score(y_test, model_pred)*100))\n",
    "    print('   Precision Score:  {:6,.1f}%'.format(prec_logistic_regression))\n",
    "    print('   Recall Score:     {:6,.1f}%'.format(recall_logistic_regression))\n",
    "    print('   F1 Score:         {:6,.1f}%'.format(f1_logistic_regression)+'\\n')\n",
    "\n",
    "    res_1 = cross_val_score(logistic_regression, X_train, y_train, scoring = 'accuracy', cv = 10)\n",
    "\n",
    "    # The confusion matrix\n",
    "    sns.set(font_scale = 1.5)\n",
    "    logistic_regression_cm = confusion_matrix(y, logistic_regression.predict(x))\n",
    "    f, ax = plt.subplots(figsize=(5,5))\n",
    "    sns.heatmap(logistic_regression_cm, \n",
    "                annot=True, \n",
    "                linewidth=0.7, \n",
    "                linecolor='black', \n",
    "                fmt='g', \n",
    "                ax=ax, \n",
    "                cmap=\"BuPu\")\n",
    "    plt.xlabel('Suit Prediction')\n",
    "    plt.ylabel('Suit Actual')\n",
    "    plt.show()\n",
    "    \n",
    "    probs = logistic_regression1.predict_proba(X_test)\n",
    "    f, ax = plt.subplots(figsize=(5, 5))\n",
    "    # Calculate the fpr and tpr for all thresholds of the classification\n",
    "    fpr, tpr, threshold = roc_curve(y_test, probs[:,1])\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "    \n",
    "    return logistic_regression, acc_logistic_regression, prec_logistic_regression, recall_logistic_regression, f1_logistic_regression\n",
    "        \n",
    "        \n",
    "def show_values(axs, orient=\"v\", space=.01):\n",
    "    def _single(ax):\n",
    "        if orient == \"v\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() / 2\n",
    "                _y = p.get_y() + p.get_height() + (p.get_height()*0.01)\n",
    "                value = '{:.0f}'.format(p.get_height())\n",
    "                ax.text(_x, _y, value, ha=\"center\") \n",
    "        elif orient == \"h\":\n",
    "            for p in ax.patches:\n",
    "                _x = p.get_x() + p.get_width() + float(space)\n",
    "                _y = p.get_y() + p.get_height() - (p.get_height()*0.5)\n",
    "                value = '{:.0f}'.format(p.get_width())\n",
    "                ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "    if isinstance(axs, np.ndarray):\n",
    "        for idx, ax in np.ndenumerate(axs):\n",
    "            _single(ax)\n",
    "    else:\n",
    "        _single(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Index gvkey invalid",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ed9688fde179>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'y_train.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'y_test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mX_train_smote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'X_train_smote.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my_train_smote\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_loc\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'y_train_smote.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gvkey'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2134\u001b[0m             \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_date_conversions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2135\u001b[1;33m             \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2137\u001b[0m         \u001b[1;31m# maybe create a mi on the columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_index\u001b[1;34m(self, data, alldata, columns, indexnamerow)\u001b[0m\n\u001b[0;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1578\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1579\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_simple_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malldata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1580\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_has_complex_date_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_get_simple_index\u001b[1;34m(self, data, columns)\u001b[0m\n\u001b[0;32m   1609\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1611\u001b[1;33m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1612\u001b[0m             \u001b[0mto_remove\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m             \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mix\u001b[1;34m(col)\u001b[0m\n\u001b[0;32m   1604\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1605\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1606\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Index {col} invalid\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1608\u001b[0m         \u001b[0mto_remove\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Index gvkey invalid"
     ]
    }
   ],
   "source": [
    "folder_loc = '../01_data/02_modified/'\n",
    "X_train = pd.read_csv(folder_loc+'X_train.csv', index_col='gvkey')\n",
    "X_test = pd.read_csv(folder_loc+'X_test.csv', index_col='gvkey')\n",
    "y_train = pd.read_csv(folder_loc+'y_train.csv', index_col='gvkey')\n",
    "y_test = pd.read_csv(folder_loc+'y_test.csv', index_col='gvkey')\n",
    "X_train_smote = pd.read_csv(folder_loc+'X_train_smote.csv', index_col='gvkey')\n",
    "y_train_smote = pd.read_csv(folder_loc+'y_train_smote.csv', index_col='gvkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gvkey</th>\n",
       "      <th>Vol_at_Variance</th>\n",
       "      <th>Vol_capx_Variance</th>\n",
       "      <th>Vol_cshfd_Variance</th>\n",
       "      <th>Vol_emp_Variance</th>\n",
       "      <th>Vol_epspi_Variance</th>\n",
       "      <th>Vol_ni_Variance</th>\n",
       "      <th>Vol_sale_Variance</th>\n",
       "      <th>Vol_teq_Variance</th>\n",
       "      <th>Vol_wcap_Variance</th>\n",
       "      <th>Vol_roa_Variance</th>\n",
       "      <th>Vol_roe_Variance</th>\n",
       "      <th>StdDev_cshfd</th>\n",
       "      <th>StdDev_emp</th>\n",
       "      <th>StdDev_epspi</th>\n",
       "      <th>StdDev_wcap</th>\n",
       "      <th>StdDev_xido</th>\n",
       "      <th>StdDev_roa</th>\n",
       "      <th>StdDev_roe</th>\n",
       "      <th>at_PercentChange</th>\n",
       "      <th>capx_PercentChange</th>\n",
       "      <th>cogs_PercentChange</th>\n",
       "      <th>dp_PercentChange</th>\n",
       "      <th>emp_PercentChange</th>\n",
       "      <th>epspi_PercentChange</th>\n",
       "      <th>ni_PercentChange</th>\n",
       "      <th>sale_PercentChange</th>\n",
       "      <th>txt_PercentChange</th>\n",
       "      <th>wcap_PercentChange</th>\n",
       "      <th>xido_PercentChange</th>\n",
       "      <th>xint_PercentChange</th>\n",
       "      <th>roe_PercentChange</th>\n",
       "      <th>Foreign_and_Domestic_indicator</th>\n",
       "      <th>GIC_SI_Agricultural_Farm_Machinery</th>\n",
       "      <th>GIC_SI_Construction_Engineering</th>\n",
       "      <th>GIC_SI_Construction_Farm_Machinery_Heavy_Trucks</th>\n",
       "      <th>GIC_SI_Electrical_Components_Equipment</th>\n",
       "      <th>GIC_SI_Heavy_Electrical_Equipment</th>\n",
       "      <th>GIC_SI_Industrial_Conglomerates</th>\n",
       "      <th>GIC_SI_Industrial_Machinary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142499</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12722</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135844</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4807</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18799</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>161843</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>237820</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.14</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>17420</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>2.35</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>11703</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>8958</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gvkey  Vol_at_Variance  Vol_capx_Variance  Vol_cshfd_Variance  Vol_emp_Variance  Vol_epspi_Variance  Vol_ni_Variance  Vol_sale_Variance  Vol_teq_Variance  Vol_wcap_Variance  Vol_roa_Variance  Vol_roe_Variance  StdDev_cshfd  StdDev_emp  StdDev_epspi  StdDev_wcap  StdDev_xido  StdDev_roa  StdDev_roe  at_PercentChange  capx_PercentChange  cogs_PercentChange  dp_PercentChange  emp_PercentChange  epspi_PercentChange  ni_PercentChange  sale_PercentChange  txt_PercentChange  wcap_PercentChange  xido_PercentChange  xint_PercentChange  roe_PercentChange  Foreign_and_Domestic_indicator  GIC_SI_Agricultural_Farm_Machinery  GIC_SI_Construction_Engineering  GIC_SI_Construction_Farm_Machinery_Heavy_Trucks  GIC_SI_Electrical_Components_Equipment  GIC_SI_Heavy_Electrical_Equipment  GIC_SI_Industrial_Conglomerates  GIC_SI_Industrial_Machinary\n",
       "0   142499             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.72        0.31          0.39         0.38         0.18        0.10        0.10              0.00               -0.12                0.01             -0.03               0.00                 0.00              0.00                0.00               0.00               -0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       0                                  0                                0                            1\n",
       "1    12722             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.13        0.31          0.36         0.38         0.19        0.10        0.18              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       0                                  0                                0                            1\n",
       "2   135844             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.13        0.30          0.36         0.35         0.19        0.10        0.18              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00              -0.00                0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       0                                  0                                0                            0\n",
       "3     4807             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.12        0.30          0.32         0.34         0.18        0.10        0.17              0.00                0.00                0.00              0.00               0.00                -0.00             -0.00                0.00              -0.00                0.00               -0.00                0.00              -0.00                               0                                   0                                0                                                0                                       0                                  0                                0                            1\n",
       "4    18799             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.14        0.31          0.39         0.38         0.19        0.10        0.18              0.00                0.00                0.00              0.00               0.00                -0.00             -0.00                0.00               0.00               -0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       0                                  1                                0                            0\n",
       "..     ...              ...                ...                 ...               ...                 ...              ...                ...               ...                ...               ...               ...           ...         ...           ...          ...          ...         ...         ...               ...                 ...                 ...               ...                ...                  ...               ...                 ...                ...                 ...                 ...                 ...                ...                             ...                                 ...                              ...                                              ...                                     ...                                ...                              ...                          ...\n",
       "89  161843             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.13        0.28          0.25         0.32         0.19        0.10        0.18              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               0                                   0                                0                                                1                                       0                                  0                                0                            0\n",
       "90  237820             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.14        3.00          0.38         0.22         0.19        0.10        0.18              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               1                                   0                                1                                                0                                       0                                  0                                0                            0\n",
       "91   17420             0.05               0.04                0.01              0.06                0.05             0.03               0.00              0.06               0.07              0.06              0.01          0.13        0.47          0.29         2.35         0.19        0.10        0.17              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               1                                   0                                0                                                0                                       0                                  0                                0                            1\n",
       "92   11703             0.06               0.04                0.44              0.06                0.05             0.07               0.00              0.05               0.07              0.05              0.33          0.02        0.31          0.38         0.38         0.19        0.08        0.09              0.00                0.00                0.00              0.00               0.00                 0.00              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       1                                  0                                0                            0\n",
       "93    8958             0.05               0.04                0.23              0.02                0.04             0.03               0.00              0.06               0.07              0.06              0.01          0.09        0.27          0.09         0.32         0.19        0.10        0.18              0.00                0.00                0.00              0.00              -0.11                -0.50              0.00                0.00               0.00                0.00                0.00                0.00               0.00                               0                                   0                                0                                                0                                       0                                  0                                1                            0\n",
       "\n",
       "[94 rows x 40 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (664, 40)\n",
      "y_train.shape:  (664, 2)\n",
      "X_test.shape:  (94, 40)\n",
      "                     Generalized Linear Model Regression Results                      \n",
      "======================================================================================\n",
      "Dep. Variable:     ['Unnamed: 0', 'suitflag']   No. Observations:                  664\n",
      "Model:                                    GLM   Df Residuals:                      623\n",
      "Model Family:                        Binomial   Df Model:                           40\n",
      "Link Function:                          logit   Scale:                          1.0000\n",
      "Method:                                  IRLS   Log-Likelihood:                -449.87\n",
      "Date:                        Wed, 03 Nov 2021   Deviance:                       239.38\n",
      "Time:                                22:06:59   Pearson chi2:                 1.78e+03\n",
      "No. Iterations:                            14                                         \n",
      "Covariance Type:                    nonrobust                                         \n",
      "===================================================================================================================\n",
      "                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "const                                               6.0885      0.604     10.072      0.000       4.904       7.273\n",
      "Unnamed: 0                                         -0.0007      0.000     -1.547      0.122      -0.002       0.000\n",
      "Vol_at_Variance                                    -0.4419      0.773     -0.572      0.568      -1.957       1.073\n",
      "Vol_capx_Variance                                  -0.6003      0.661     -0.908      0.364      -1.895       0.695\n",
      "Vol_cshfd_Variance                                  0.3650      0.390      0.936      0.349      -0.400       1.130\n",
      "Vol_emp_Variance                                    0.7814      0.733      1.066      0.287      -0.656       2.218\n",
      "Vol_epspi_Variance                                  2.1204      4.196      0.505      0.613      -6.103      10.344\n",
      "Vol_ni_Variance                                     1.4937      0.934      1.598      0.110      -0.338       3.325\n",
      "Vol_sale_Variance                                   0.1752      0.455      0.385      0.700      -0.716       1.067\n",
      "Vol_teq_Variance                                   -0.8750      1.109     -0.789      0.430      -3.049       1.299\n",
      "Vol_wcap_Variance                                  -0.2779      0.577     -0.482      0.630      -1.409       0.853\n",
      "Vol_roa_Variance                                   -1.5879      1.324     -1.199      0.231      -4.184       1.008\n",
      "Vol_roe_Variance                                    8.9630      5.965      1.503      0.133      -2.729      20.655\n",
      "StdDev_cshfd                                       -1.3460      0.984     -1.368      0.171      -3.274       0.582\n",
      "StdDev_emp                                         -0.2736      0.259     -1.055      0.292      -0.782       0.235\n",
      "StdDev_epspi                                       -0.4229      0.266     -1.590      0.112      -0.944       0.098\n",
      "StdDev_wcap                                         0.1309      0.192      0.681      0.496      -0.246       0.508\n",
      "StdDev_xido                                        -0.1246      0.185     -0.673      0.501      -0.488       0.239\n",
      "StdDev_roa                                          8.3829      5.251      1.596      0.110      -1.909      18.674\n",
      "StdDev_roe                                          0.7434      0.650      1.144      0.253      -0.530       2.017\n",
      "at_PercentChange                                   -1.1379      3.572     -0.319      0.750      -8.139       5.863\n",
      "capx_PercentChange                                 -3.6493      2.743     -1.330      0.183      -9.025       1.727\n",
      "cogs_PercentChange                                  0.2452      0.481      0.510      0.610      -0.698       1.188\n",
      "dp_PercentChange                                   -0.4604      1.075     -0.428      0.669      -2.568       1.647\n",
      "emp_PercentChange                                  -0.2986      1.484     -0.201      0.841      -3.207       2.609\n",
      "epspi_PercentChange                                -0.1370      0.144     -0.954      0.340      -0.418       0.144\n",
      "ni_PercentChange                                   -0.6432      0.628     -1.024      0.306      -1.874       0.588\n",
      "sale_PercentChange                                  0.6103      1.428      0.427      0.669      -2.189       3.410\n",
      "txt_PercentChange                                  -0.0189      0.048     -0.395      0.693      -0.113       0.075\n",
      "wcap_PercentChange                                  0.0040      0.083      0.049      0.961      -0.158       0.167\n",
      "xido_PercentChange                                 -0.0895      0.099     -0.904      0.366      -0.284       0.105\n",
      "xint_PercentChange                                 -0.5813      1.421     -0.409      0.682      -3.366       2.203\n",
      "roe_PercentChange                                   0.6540      0.433      1.511      0.131      -0.194       1.502\n",
      "Foreign_and_Domestic_indicator                     -0.0078      0.243     -0.032      0.974      -0.484       0.468\n",
      "GIC_SI_Agricultural_Farm_Machinery                  0.3850      1.028      0.375      0.708      -1.629       2.399\n",
      "GIC_SI_Construction_Engineering                    -0.0493      0.233     -0.212      0.832      -0.506       0.408\n",
      "GIC_SI_Construction_Farm_Machinery_Heavy_Trucks     0.2761      0.274      1.008      0.313      -0.261       0.813\n",
      "GIC_SI_Electrical_Components_Equipment              0.0188      0.162      0.116      0.908      -0.300       0.337\n",
      "GIC_SI_Heavy_Electrical_Equipment                  -0.1857      0.271     -0.685      0.493      -0.717       0.345\n",
      "GIC_SI_Industrial_Conglomerates                     0.6315      1.107      0.571      0.568      -1.538       2.801\n",
      "GIC_SI_Industrial_Machinary                         0.7984      0.281      2.842      0.004       0.248       1.349\n",
      "===================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape: ', X_train_smote.shape)\n",
    "print('y_train.shape: ', y_train_smote.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "# Logistic regression model\n",
    "logm1 = stats.GLM(y_train_smote,(stats.add_constant(X_train_smote)), family = stats.families.Binomial())\n",
    "print(logm1.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep 'Vol_at_Variance', 'Vol_ni_Variance', 'Vol_roa_Variance', 'Vol_roe_Variance', 'StdDev_emp', 'StdDev_xido', 'StdDev_roa', 'StdDev_roe', \n",
    "'capx_PercentChange','sale_PercentChange', 'sale_PercentChange', 'wcap_PercentChange', \n",
    "'Foreign_and_Domestic_indicator','GIC_SI_Agricultural_Farm_Machinery', 'GIC_SI_Construction_Engineering', \n",
    "'GIC_SI_Construction_Farm_Machinery_Heavy_Trucks', 'GIC_SI_Electrical_Components_Equipment', 'GIC_SI_Industrial_Conglomerates', 'GIC_SI_Industrial_Machinary'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Run Results - without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_model_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-831913d08248>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlogistic_regression1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc_logistic_regression1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprec_logistic_regression1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_logistic_regression1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_logistic_regression1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_model_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'log_model_run' is not defined"
     ]
    }
   ],
   "source": [
    "logistic_regression1, acc_logistic_regression1, prec_logistic_regression1, recall_logistic_regression1, f1_logistic_regression1 = log_model_run(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression1, acc_logistic_regression1, prec_logistic_regression1, recall_logistic_regression1, f1_logistic_regression1 = log_model_run(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(model, feature_names):\n",
    "    feature_imp = pd.Series(model.coef_[0],index=feature_names).sort_values(ascending=False)\n",
    "    sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "    plt.xlabel('Feature Coefficients')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Visualizing Important Features')\n",
    "    plt.show()\n",
    "    print(feature_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_features(logistic_regression1, x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression2, acc_logistic_regression2, prec_logistic_regression2, recall_logistic_regression2, f1_logistic_regression2 = log_model_run(X_train_sm, y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Review: </b>There are a total of  variables that are significant. Below are the variables to select when re-running the model:\n",
    "\n",
    "    'Vol_capx_Variance', 'Vol_teq_Variance', 'Vol_roa_Variance', 'StdDev_emp', 'StdDev_epspi', 'StdDev_wcap', 'StdDev_xido', 'StdDev_roe', \n",
    "    'capx_PercentChange', 'epspi_PercentChange', 'sale_PercentChange', 'sale_PercentChange', 'txt_PercentChange', 'wcap_PercentChange', \n",
    "    'xido_PercentChange', 'roe_PercentChange', 'GIC_SI_Agricultural_Farm_Machinery', 'GIC_SI_Construction_Engineering', \n",
    "    'GIC_SI_Construction_Farm_Machinery_Heavy_Trucks', 'GIC_SI_Electrical_Components_Equipment', 'GIC_SI_Heavy_Electrical_Equipment',\n",
    "    'GIC_SI_Industrial_Machinary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Second Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_variables = ['Vol_capx_Variance', 'Vol_teq_Variance', 'Vol_roa_Variance', 'StdDev_emp', 'StdDev_epspi', 'StdDev_wcap', 'StdDev_xido', 'StdDev_roe', \n",
    "                 'capx_PercentChange', 'epspi_PercentChange', 'sale_PercentChange', 'sale_PercentChange', 'txt_PercentChange', 'wcap_PercentChange', \n",
    "                 'xido_PercentChange', 'roe_PercentChange', 'GIC_SI_Agricultural_Farm_Machinery', 'GIC_SI_Construction_Engineering', \n",
    "                 'GIC_SI_Construction_Farm_Machinery_Heavy_Trucks', 'GIC_SI_Electrical_Components_Equipment', 'GIC_SI_Heavy_Electrical_Equipment', 'GIC_SI_Industrial_Machinary', \n",
    "                 'suitflag']\n",
    "df3 = df2[sig_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Data Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df3.corr()\n",
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)]= True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "heatmap = sns.heatmap(corr_matrix,\n",
    "                      mask = mask,\n",
    "                      square = True,\n",
    "                      linewidths = .5,\n",
    "                      cmap = 'coolwarm',\n",
    "                      cbar_kws = {'shrink': .4,\n",
    "                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n",
    "                      vmin = -1,\n",
    "                      vmax = 1,\n",
    "                      annot = True)\n",
    "\n",
    "\n",
    "#add the column names as labels\n",
    "ax.set_yticklabels(corr_matrix.columns, rotation = 0)\n",
    "ax.set_xticklabels(corr_matrix.columns)\n",
    "\n",
    "sns.set_style({'xtick.bottom': True}, {'ytick.left': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output any correlated values over 0.65 - isolating high-correlated variables to remove from the analysis\n",
    "def high_corr_and_check(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), \n",
    "                                     k=1).astype(np.bool))\n",
    "                      .stack()\n",
    "                      .sort_values(ascending=False))\n",
    "    for index, value in sol.items():\n",
    "        if value > 0.65:\n",
    "            print(index,value)\n",
    "            \n",
    "high_corr_and_check(df3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Action: </b>There are no highly correlated variables I believe would help the analysis to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df3.drop(columns='suitflag')\n",
    "\n",
    "y = df3[['suitflag']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y,\n",
    "                                                   test_size=0.45,\n",
    "                                                   random_state=16,\n",
    "                                                   stratify=y)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "logm2 = sm.GLM(y_train,(sm.add_constant(X_train)), \n",
    "               family = sm.families.Binomial())\n",
    "print(logm2.fit().summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression2 = LogisticRegression(n_jobs=-1, random_state=15)\n",
    "logistic_regression2.fit(X_train, y_train)\n",
    "\n",
    "acc_logistic_regression2 = round(logistic_regression2.score(X_test, y_test) * 100, 2)\n",
    "prec_logistic_regression2 = round(precision_score(y_pred=logistic_regression2.predict(X_test), y_true=y_test)* 100, 2)\n",
    "recall_logistic_regression2 = round(recall_score(y_pred=logistic_regression2.predict(X_test), y_true=y_test)* 100, 2)\n",
    "f1_logistic_regression2 = round(f1_score(y_pred=logistic_regression2.predict(X_test), y_true=y_test)* 100, 2)\n",
    "\n",
    "print_score(logistic_regression2, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(logistic_regression2, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "res_2 = cross_val_score(logistic_regression2, X_train, y_train, scoring = 'accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "sns.set(font_scale = 1.5)\n",
    "logistic_regression_cm = confusion_matrix(y_test, \n",
    "                                          logistic_regression2.predict(X_test))\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(logistic_regression_cm, \n",
    "            annot=True, \n",
    "            linewidth=0.7, \n",
    "            linecolor='black', \n",
    "            fmt='g', \n",
    "            ax=ax, \n",
    "            cmap=\"BuPu\")\n",
    "plt.title('Logistic Regression - Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logistic_regression2.predict_proba(X_test)\n",
    "# Calculate the fpr and tpr for all thresholds of the classification\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs[:,1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Review: </b>After a second model run, I am going to drop the following columns and re-run:\n",
    "\n",
    "1) Vol_roe_Variance\n",
    "2) GIC_SubIndustry_Heavy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression - Third Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(columns=['Vol_emp_Variance', 'Vol_wcap_Variance', 'StdDev_wcap', 'StdDev_cogs','GIC_SI_Construction_Engineering',])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Data Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = df4.corr()\n",
    "mask = np.zeros_like(corr_matrix, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)]= True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "sns.set(font_scale = 1.3)\n",
    "\n",
    "heatmap = sns.heatmap(corr_matrix,\n",
    "                      mask = mask,\n",
    "                      square = True,\n",
    "                      linewidths = .5,\n",
    "                      cmap = 'coolwarm',\n",
    "                      cbar_kws = {'shrink': .4,\n",
    "                                'ticks' : [-1, -.5, 0, 0.5, 1]},\n",
    "                      vmin = -1,\n",
    "                      vmax = 1,\n",
    "                      annot = True)\n",
    "\n",
    "\n",
    "#add the column names as labels\n",
    "ax.set_yticklabels(corr_matrix.columns, rotation = 0)\n",
    "ax.set_xticklabels(corr_matrix.columns)\n",
    "\n",
    "sns.set_style({'xtick.bottom': True}, {'ytick.left': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output any correlated values over 0.65 - isolating high-correlated variables to remove from the analysis\n",
    "def high_corr_and_check(X):\n",
    "    corr_matrix = X.corr().abs()\n",
    "    sol = (corr_matrix.where(np.triu(np.ones(corr_matrix.shape), \n",
    "                                     k=1).astype(np.bool))\n",
    "                      .stack()\n",
    "                      .sort_values(ascending=False))\n",
    "    for index, value in sol.items():\n",
    "        if value > 0.65:\n",
    "            print(index,value)\n",
    "            \n",
    "high_corr_and_check(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Action: </b>There are no highly correlated variables I believe would help the analysis to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df4.drop(columns='suitflag')\n",
    "\n",
    "y = df4[['suitflag']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y,\n",
    "                                                   test_size=0.46,\n",
    "                                                   random_state=16,\n",
    "                                                   stratify=y)\n",
    "\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)\n",
    "print('X_test.shape: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression model\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "\n",
    "logm3 = sm.GLM(y_train,(sm.add_constant(X_train)), \n",
    "               family = sm.families.Binomial())\n",
    "print(logm3.fit().summary())\n",
    "\n",
    "res = logm3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression3 = LogisticRegression(n_jobs=-1, random_state=15)\n",
    "logistic_regression3.fit(X_train, y_train)\n",
    "\n",
    "acc_logistic_regression3 = round(logistic_regression3.score(X_test, y_test) * 100, 2)\n",
    "prec_logistic_regression3 = round(precision_score(y_pred=logistic_regression3.predict(X_test), y_true=y_test)* 100, 2)\n",
    "recall_logistic_regression3 = round(recall_score(y_pred=logistic_regression3.predict(X_test), y_true=y_test)* 100, 2)\n",
    "f1_logistic_regression3 = round(f1_score(y_pred=logistic_regression3.predict(X_test), y_true=y_test)* 100, 2)\n",
    "\n",
    "print_score(logistic_regression3, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(logistic_regression3, X_train, y_train, X_test, y_test, train=False)\n",
    "\n",
    "res_3 = cross_val_score(logistic_regression3, X_train, y_train, scoring = 'accuracy', cv = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The confusion matrix\n",
    "sns.set(font_scale = 1.5)\n",
    "logistic_regression_cm = confusion_matrix(y_test, \n",
    "                                          logistic_regression3.predict(X_test))\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(logistic_regression_cm, \n",
    "            annot=True, \n",
    "            linewidth=0.7, \n",
    "            linecolor='black', \n",
    "            fmt='g', \n",
    "            ax=ax, \n",
    "            cmap=\"BuPu\")\n",
    "plt.title('Logistic Regression - Classification Confusion Matrix')\n",
    "plt.xlabel('Y predict')\n",
    "plt.ylabel('Y test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Review: </b>After a third model run, all variable remain significant and thus the analysis will conclude and the confusion matrix reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logistic_regression3.predict_proba(X_test)\n",
    "# Calculate the fpr and tpr for all thresholds of the classification\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs[:,1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list which contains classifiers \n",
    "classifiers = []\n",
    "classifiers.append(logistic_regression1)\n",
    "classifiers.append(logistic_regression2)\n",
    "classifiers.append(logistic_regression3)\n",
    "print('Number of Classifiers: ',len(classifiers))\n",
    "\n",
    "# Number of Cross Validations\n",
    "cv = 10\n",
    "print('Number of Cross Validations: ', cv, '\\n','-'*40)\n",
    "\n",
    "# Create a list which contains cross validation results for each classifier\n",
    "cv_results = []\n",
    "cv_results.append(res_1)\n",
    "cv_results.append(res_2)\n",
    "cv_results.append(res_3)\n",
    "\n",
    "# for classifier in classifiers:\n",
    "#     cv_results.append(cross_val_score(classifier, X_train, y_train, scoring = 'accuracy', cv = 10))\n",
    "    \n",
    "# Mean and standard deviation of cross validation results for each classifier  \n",
    "cv_mean = []\n",
    "cv_std = []\n",
    "for cv_result in cv_results:\n",
    "    cv_mean.append(round(cv_result.mean()*100,2))\n",
    "    cv_std.append(round(cv_result.std(),3))\n",
    "\n",
    "algos = ['Logistic Regression - Initial Run',\n",
    "         'Logistic Regression - Second Run',\n",
    "         'Logistic Regression - Third Run'\n",
    "        ]\n",
    "\n",
    "acc_scores = [acc_logistic_regression1,\n",
    "              acc_logistic_regression2,\n",
    "              acc_logistic_regression3\n",
    "             ]\n",
    "\n",
    "prec_scores = [prec_logistic_regression1,\n",
    "               prec_logistic_regression2,\n",
    "               prec_logistic_regression3\n",
    "              ]\n",
    "\n",
    "recall_scores = [recall_logistic_regression1,\n",
    "                 recall_logistic_regression2,\n",
    "                 recall_logistic_regression3\n",
    "                ]\n",
    "\n",
    "f1_scores = [f1_logistic_regression1,\n",
    "             f1_logistic_regression2,\n",
    "             f1_logistic_regression3\n",
    "            ]\n",
    "\n",
    "    \n",
    "cv_res = pd.DataFrame({'Algorithm': algos,\n",
    "                       'Initial Accuracy Scores': acc_scores,\n",
    "                       'Cross Validation Mean': cv_mean, \n",
    "                       'Cross Validation Std': cv_std,\n",
    "                       'Precision Score': prec_scores,\n",
    "                       'Recall Scores': recall_scores,\n",
    "                       'F1 Scores': f1_scores\n",
    "                       })\n",
    "\n",
    "cv_res.sort_values(by = 'F1 Scores', ascending = False).set_index('Algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res1 = cv_res.drop(columns='Cross Validation Std').set_index('Algorithm').T\n",
    "sns.set(font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(24,8))\n",
    "cv_res1.plot(kind='bar', ax=ax)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Percent')\n",
    "plt.legend(loc='top right')\n",
    "show_values(ax)\n",
    "plt.ylim(0, 100)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize F1 Scores to Identify the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot('F1 Scores', \n",
    "            'Algorithm', \n",
    "            data = cv_res, \n",
    "            order = cv_res.sort_values(by = 'F1 Scores', \n",
    "                                       ascending = False)['Algorithm'], \n",
    "            palette = 'Set3', \n",
    "            **{'xerr': cv_std})\n",
    "\n",
    "plt.ylabel('Algorithm')\n",
    "plt.title('F1 Scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receiver Operating Characteristic Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = logistic_regression3.predict_proba(X_test)\n",
    "# Calculate the fpr and tpr for all thresholds of the classification\n",
    "fpr, tpr, threshold = roc_curve(y_test, probs[:,1])\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine Prediction Results to Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logistic_regression3.predict_proba(x)[:, 1]\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('gvkey', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of companies in this prediction is: ' ,len(Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame({'index': df['index'], 'suit_pred': Y_pred})\n",
    "submit = submit[['suit_pred']]\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(submit)\n",
    "df.drop(columns='index', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['suitflag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(x, base=5):\n",
    "    return int(base * round(float(x)/base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Prediction_Score'] = df['suit_pred']*100\n",
    "df['Prediction_Score'] = df['Prediction_Score'].apply(lambda x: custom_round(x, base=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Prediction_Score'] = round(df['suit_pred']*100, 2)\n",
    "pd.value_counts(df['Prediction_Score'], dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist('suit_pred', bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_res1 = cv_res.drop(columns='Cross Validation Std').set_index('Algorithm').T\n",
    "sns.set(font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(24,8))\n",
    "cv_res1.plot(kind='bar', ax=ax)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Percent')\n",
    "plt.legend(loc='top right')\n",
    "show_values(ax)\n",
    "plt.ylim(0, 100)\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (25,10))\n",
    "sns.set(font_scale = 2.5)\n",
    "\n",
    "\n",
    "var = df['Prediction_Score']\n",
    "ax = sns.countplot(x = var,\n",
    "                   data = df, )\n",
    "\n",
    "show_values(ax)\n",
    "plt.ylim(0, 150)\n",
    "\n",
    "plt.ylabel('Company Count')\n",
    "plt.xlabel('Prediction Scores \\n(in %)')\n",
    "# plt.title('Company Count by Prediction Score')\n",
    "plt.xticks(rotation = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-eb90394b2475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Features\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_sm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Coefficient\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mres_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Odds_Ratio\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Coefficient\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Coefficient\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Odds_Ratio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Coefficient\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Odds_Ratio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Perc_Impact\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Odds_Ratio\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'const'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Odds_Ratio'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "model  = pd.DataFrame({\"Features\": X_train_sm.columns,\"Coefficient\":res_3.params.values})\n",
    "model[\"Odds_Ratio\"] = model[\"Coefficient\"].apply(lambda x: np.exp(x))\n",
    "model[[\"Coefficient\",\"Odds_Ratio\"]] = model[[\"Coefficient\",\"Odds_Ratio\"]].apply(lambda x: round(x,2))\n",
    "model[\"Perc_Impact\"] = model[\"Odds_Ratio\"].apply(lambda x: (x-1)*100)\n",
    "model = model.loc[model['Features']!='const'].sort_values(by='Odds_Ratio', ascending=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_int = model.drop(columns=['Perc_Impact', 'Coefficient']).set_index('Features').T\n",
    "model_int= model_int[['Vol_sale_Variance', 'StdDev_capx', 'StdDev_txt', 'GIC_SI_Heavy_Electrical_Equipment']]\n",
    "\n",
    "sns.set(font_scale = 1.8)\n",
    "fig, ax = plt.subplots(figsize=(24,8))\n",
    "model_int.plot(kind='bar', ax=ax)\n",
    "plt.xticks(rotation = 45)\n",
    "plt.ylabel('Percent')\n",
    "plt.legend(loc='top right')\n",
    "ax.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../01_data/03_final/suit_prediction_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
